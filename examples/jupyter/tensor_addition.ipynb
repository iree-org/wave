{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "866d36f8",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa32231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clone the wave github repo\n",
    "!git clone https://github.com/iree-org/wave.git\n",
    "# install ROCm Pytorch dependencies\n",
    "!pip install -r pytorch-rocm-requirements.txt\n",
    "# install wave and its dependencies\n",
    "!pip install wave-lang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52993703",
   "metadata": {},
   "source": [
    "### Wave Tensor/Matrix Addition Kernel Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55e18af",
   "metadata": {},
   "source": [
    "#### (1) Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b636039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import wave_lang.kernel.wave as tkw\n",
    "from wave_lang.kernel._support.dtype import f16\n",
    "from wave_lang.kernel._support.indexing import sym\n",
    "from wave_lang.kernel.lang.global_symbols import *\n",
    "from wave_lang.kernel.lang.wave_types import *\n",
    "from wave_lang.kernel.wave.compile import WaveCompileOptions, wave_compile\n",
    "from wave_lang.kernel.wave.utils.run_utils import set_default_run_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e169cc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define symbolic dimensions for our matrices\n",
    "M = sym.M # Rows of A, B and C\n",
    "N = sym.N # Cols of A, B and C\n",
    "\n",
    "# Define workgroup tile sizes\n",
    "BLOCK_M = sym.BLOCK_M\n",
    "BLOCK_N = sym.BLOCK_N\n",
    "\n",
    "# Define the address space for our memory buffers\n",
    "ADDRESS_SPACE_A = sym.ADDRESS_SPACE_A\n",
    "ADDRESS_SPACE_B = sym.ADDRESS_SPACE_B\n",
    "ADDRESS_SPACE_C = sym.ADDRESS_SPACE_C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f8cd53",
   "metadata": {},
   "source": [
    "#### (2) Constraints\n",
    "To specify how we want to distribute the different dimensions of our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ef23d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constraints for the kernel\n",
    "constraints = [\n",
    "    # specifies how computation is tiled\n",
    "    tkw.WorkgroupConstraint(M, BLOCK_M, 0),\n",
    "    tkw.WorkgroupConstraint(N, BLOCK_N, 1),\n",
    "    tkw.WaveConstraint(M, BLOCK_M / 2),\n",
    "    tkw.WaveConstraint(N, BLOCK_N / 2),\n",
    "    tkw.HardwareConstraint(\n",
    "        threads_per_wave=64,\n",
    "        vector_shapes={M: BLOCK_M, N: BLOCK_N}\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399e2fd2",
   "metadata": {},
   "source": [
    "#### (3) Kernel Definition\n",
    "Our tensor addition example with compute C = A + B. They are 2D matrices of dimension MxN in f16 precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db5ed64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The kernel\n",
    "@tkw.wave(constraints)\n",
    "def matrix_add(\n",
    "    # defines matrix in memory of req dimension with specific data types\n",
    "    a: Memory[M, N, ADDRESS_SPACE_A, f16],\n",
    "    b: Memory[M, N, ADDRESS_SPACE_B, f16],\n",
    "    c: Memory[M, N, ADDRESS_SPACE_C, f16],\n",
    "):\n",
    "    # Intialize the accumulator register with zeroes\n",
    "    c_reg = Register[M,N,f16](0.0)\n",
    "\n",
    "    # loads values from memory into registers\n",
    "    a_reg = tkw.read(a)\n",
    "    b_reg = tkw.read(b)\n",
    "\n",
    "    # compute the sum\n",
    "    c_reg = a_reg + b_reg\n",
    "    \n",
    "    # writing results back to memory\n",
    "    tkw.write(c_reg, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e6e72e",
   "metadata": {},
   "source": [
    "#### (4) Testing the kernel \n",
    "A function to verify our implementation works by comparing with PyTorch reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97168291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The kernel testing function\n",
    "def test_gemm():\n",
    "    # Create test matrices\n",
    "    m, n = 128, 128\n",
    "\n",
    "    # Initialize input matrices with random values\n",
    "    torch.manual_seed(0)\n",
    "    a = torch.randn(m, n, dtype=torch.float16, device=\"cuda\")\n",
    "    b = torch.zeros(m, n, dtype=torch.float16, device=\"cuda\")\n",
    "    c = torch.zeros(m, n, dtype=torch.float16, device=\"cuda\")\n",
    "\n",
    "    # Set hyperparameters for compilation\n",
    "    hyperparams = {\n",
    "        ADDRESS_SPACE_A: SHARED_ADDRESS_SPACE,\n",
    "        ADDRESS_SPACE_B: SHARED_ADDRESS_SPACE,\n",
    "        ADDRESS_SPACE_C: GLOBAL_ADDRESS_SPACE,\n",
    "        BLOCK_M: 64,\n",
    "        BLOCK_N: 64,\n",
    "        M: m,\n",
    "        N: n\n",
    "    }\n",
    "\n",
    "    # Compile the kernel\n",
    "    options = WaveCompileOptions(\n",
    "        subs=hyperparams,\n",
    "    )\n",
    "    options = set_default_run_config(options)\n",
    "    compiled_gemm = wave_compile(options, matrix_add)\n",
    "\n",
    "    # Run the Tensor Addition kernel\n",
    "    mlir = compiled_gemm(a, b, c)\n",
    "\n",
    "    # Verify the result using PyTorch's matmul\n",
    "    expected = a + b\n",
    "\n",
    "    # Check if results are close (accounting for floating-point precision)\n",
    "    assert torch.allclose(c.to(torch.float16), expected, rtol=1e-2, atol=1e-2), \\\n",
    "        f\"Tensor Addition result doesn't match expected output\\nMax difference: {(c - expected).abs().max()}\"    \n",
    "\n",
    "    print(\"Tensor Addition test passed!\")\n",
    "\n",
    "    # print(mlir) - if you want to see the generated mlir\n",
    "\n",
    "# Run the test\n",
    "test_gemm()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wavenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
